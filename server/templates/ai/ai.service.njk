import { Injectable, Logger, BadRequestException } from '@nestjs/common';
{% if ai.providers | includes('openai') %}
import OpenAI from 'openai';
{% endif %}
{% if ai.providers | includes('anthropic') %}
import Anthropic from '@anthropic-ai/sdk';
{% endif %}

export interface EmbeddingResult {
  vector: number[];
  dimensions: number;
}

export interface ChatCompletionResult {
  content: string;
  usage?: {
    promptTokens: number;
    completionTokens: number;
    totalTokens: number;
  };
}

export interface ModerationResult {
  flagged: boolean;
  categories: Record<string, boolean>;
  categoryScores: Record<string, number>;
}

/**
 * AI Service
 * 
 * Provides AI/ML capabilities:
 * - Text embeddings (for semantic search)
 * - Chat completions (content generation)
 * - Content moderation
 * - Summarization
 * 
 * Supports: OpenAI, Anthropic (Claude)
 * 
 * Environment Variables:
 * - OPENAI_API_KEY: OpenAI API key
 * - ANTHROPIC_API_KEY: Anthropic API key
 */
@Injectable()
export class AiService {
  private readonly logger = new Logger(AiService.name);
{% if ai.providers | includes('openai') %}
  private readonly openai: OpenAI;
{% endif %}
{% if ai.providers | includes('anthropic') %}
  private readonly anthropic: Anthropic;
{% endif %}

  constructor() {
{% if ai.providers | includes('openai') %}
    this.openai = new OpenAI({
      apiKey: process.env.OPENAI_API_KEY,
    });
{% endif %}
{% if ai.providers | includes('anthropic') %}
    this.anthropic = new Anthropic({
      apiKey: process.env.ANTHROPIC_API_KEY,
    });
{% endif %}
  }

{% if ai.features.embeddings %}
  /**
   * Generate text embeddings for semantic search
   */
  async createEmbedding(text: string): Promise<EmbeddingResult> {
{% if ai.providers | includes('openai') %}
    try {
      const response = await this.openai.embeddings.create({
        model: 'text-embedding-3-small',
        input: text,
      });

      return {
        vector: response.data[0].embedding,
        dimensions: response.data[0].embedding.length,
      };
    } catch (error) {
      this.logger.error(`Embedding failed: ${error.message}`);
      throw new BadRequestException('Failed to create embedding');
    }
{% else %}
    throw new BadRequestException('Embeddings not supported without OpenAI');
{% endif %}
  }

  /**
   * Batch create embeddings for multiple texts
   */
  async createEmbeddings(texts: string[]): Promise<EmbeddingResult[]> {
{% if ai.providers | includes('openai') %}
    try {
      const response = await this.openai.embeddings.create({
        model: 'text-embedding-3-small',
        input: texts,
      });

      return response.data.map(item => ({
        vector: item.embedding,
        dimensions: item.embedding.length,
      }));
    } catch (error) {
      this.logger.error(`Batch embedding failed: ${error.message}`);
      throw new BadRequestException('Failed to create embeddings');
    }
{% else %}
    throw new BadRequestException('Embeddings not supported without OpenAI');
{% endif %}
  }
{% endif %}

  /**
   * Generate chat completion
   */
  async chatCompletion(params: {
    messages: { role: 'system' | 'user' | 'assistant'; content: string }[];
    model?: string;
    maxTokens?: number;
    temperature?: number;
  }): Promise<ChatCompletionResult> {
    const { messages, model, maxTokens = 1000, temperature = 0.7 } = params;

{% if ai.providers | includes('openai') %}
    try {
      const response = await this.openai.chat.completions.create({
        model: model || 'gpt-4o-mini',
        messages,
        max_tokens: maxTokens,
        temperature,
      });

      return {
        content: response.choices[0]?.message?.content || '',
        usage: {
          promptTokens: response.usage?.prompt_tokens || 0,
          completionTokens: response.usage?.completion_tokens || 0,
          totalTokens: response.usage?.total_tokens || 0,
        },
      };
    } catch (error) {
      this.logger.error(`Chat completion failed: ${error.message}`);
      throw new BadRequestException('Failed to generate completion');
    }
{% elif ai.providers | includes('anthropic') %}
    try {
      const systemMessage = messages.find(m => m.role === 'system')?.content || '';
      const chatMessages = messages.filter(m => m.role !== 'system');

      const response = await this.anthropic.messages.create({
        model: model || 'claude-3-haiku-20240307',
        max_tokens: maxTokens,
        system: systemMessage,
        messages: chatMessages.map(m => ({
          role: m.role as 'user' | 'assistant',
          content: m.content,
        })),
      });

      const textContent = response.content.find(c => c.type === 'text');
      
      return {
        content: textContent?.text || '',
        usage: {
          promptTokens: response.usage?.input_tokens || 0,
          completionTokens: response.usage?.output_tokens || 0,
          totalTokens: (response.usage?.input_tokens || 0) + (response.usage?.output_tokens || 0),
        },
      };
    } catch (error) {
      this.logger.error(`Chat completion failed: ${error.message}`);
      throw new BadRequestException('Failed to generate completion');
    }
{% else %}
    throw new BadRequestException('No AI provider configured');
{% endif %}
  }

{% if ai.features.summarization %}
  /**
   * Summarize text content
   */
  async summarize(text: string, maxLength = 200): Promise<string> {
    const result = await this.chatCompletion({
      messages: [
        { role: 'system', content: `Summarize the following text in under ${maxLength} characters. Be concise and capture the key points.` },
        { role: 'user', content: text },
      ],
      maxTokens: 500,
      temperature: 0.3,
    });

    return result.content;
  }
{% endif %}

{% if ai.features.moderation %}
  /**
   * Check content for policy violations
   */
  async moderate(text: string): Promise<ModerationResult> {
{% if ai.providers | includes('openai') %}
    try {
      const response = await this.openai.moderations.create({
        input: text,
      });

      const result = response.results[0];
      return {
        flagged: result.flagged,
        categories: result.categories as Record<string, boolean>,
        categoryScores: result.category_scores as Record<string, number>,
      };
    } catch (error) {
      this.logger.error(`Moderation failed: ${error.message}`);
      throw new BadRequestException('Failed to moderate content');
    }
{% else %}
    // Basic keyword-based moderation fallback
    const badWords = ['spam', 'scam']; // Add more as needed
    const flagged = badWords.some(word => text.toLowerCase().includes(word));
    return {
      flagged,
      categories: { harmful: flagged },
      categoryScores: { harmful: flagged ? 1 : 0 },
    };
{% endif %}
  }
{% endif %}

{% if ai.features.recommendations %}
  /**
   * Generate recommendations based on user context
   */
  async getRecommendations(params: {
    userId: string;
    context: string;
    itemType: string;
    limit?: number;
  }): Promise<string[]> {
    const { context, itemType, limit = 5 } = params;
    
    const result = await this.chatCompletion({
      messages: [
        { 
          role: 'system', 
          content: `You are a recommendation system. Based on the user context, suggest ${limit} ${itemType}s. Return ONLY a JSON array of strings with the recommendations. No explanations.` 
        },
        { role: 'user', content: `Context: ${context}` },
      ],
      maxTokens: 500,
      temperature: 0.8,
    });

    try {
      return JSON.parse(result.content);
    } catch {
      this.logger.warn('Failed to parse AI recommendations response');
      return [];
    }
  }
{% endif %}
}
